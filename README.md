ğŸš€ Bitcoin ETL Data Pipeline | PySpark â€¢ Databricks â€¢ Delta Lake

Production-ready Data Engineering project that builds an automated ETL pipeline to ingest real-time cryptocurrency and FX data, process it at scale, and deliver analytics-ready data for dashboards.

Built with Python, PySpark, Databricks, Unity Catalog, and Delta Lake.

ğŸ” Project Summary (TL;DR)

ğŸ”„ End-to-End ETL Pipeline

ğŸŒ Real-time API ingestion

âš™ï¸ Automated with Databricks Workflows

ğŸ§± ACID-compliant Delta Tables

ğŸ“Š Analytics & dashboard-ready SQL layer

â˜ï¸ Cloud-native, scalable architecture

ğŸ—ï¸ Architecture Overview
Coinbase API + CurrencyFreaks API
              â†“
        PySpark ETL
              â†“
   Delta Lake (Unity Catalog)
              â†“
        SQL Analytics
              â†“
          Dashboard

ğŸ¯ Business Use Case

Track Bitcoin price trends in Brazilian Real (BRL)

Maintain historical price data with full auditability

Enable real-time monitoring and analytics

Designed to scale from small workloads to Big Data

ğŸ”„ ETL Workflow
1ï¸âƒ£ Extract

Bitcoin price (USD) from Coinbase API

USD â†’ BRL exchange rate from CurrencyFreaks

Robust API handling (JSON parsing, error handling)

2ï¸âƒ£ Transform

Currency conversion (USD â†’ BRL)

Data type normalization

Timestamp enrichment

Schema standardization

3ï¸âƒ£ Load

Stored as Delta Tables in Databricks

Managed with Unity Catalog

Incremental append (historical tracking)

Schema evolution enabled

ğŸ“Š Data Model (Delta Table)
Column	Type	Description
valor_usd	DOUBLE	Bitcoin price (USD)
valor_brl	DOUBLE	Bitcoin price (BRL)
criptomoeda	STRING	BTC
moeda_original	STRING	USD
taxa_conversao_usd_brl	DOUBLE	FX rate
timestamp	TIMESTAMP	Ingestion time
ğŸ“ˆ Analytics & Dashboard Queries

Latest Bitcoin price

Historical max price

Historical min price

Time-series price evolution

All analytics are powered by SQL directly on Delta Lake, enabling fast queries and BI integration.

âš™ï¸ Automation & Orchestration

Databricks Jobs & Workflows

Parameterized execution (API Keys)

Manual or scheduled runs

Execution logs and monitoring

ğŸ§° Tech Stack

Python 3.8+

PySpark

Requests

Databricks

Delta Lake

Unity Catalog

ğŸ“‚ Repository Structure
pipeline-api-bitcoin-com-databricks/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ get_bitcoin_full.py      # Full ETL with documentation
â”‚   â”œâ”€â”€ get_bitcoin_macro.py     # Production workflow version
â”‚   â”œâ”€â”€ aquecimento_python.py    # Python fundamentals
â”‚   â””â”€â”€ aquecimento_sql.py       # SQL fundamentals
â”œâ”€â”€ img/
â”‚   â””â”€â”€ cover.png
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

ğŸ” Security & Best Practices

API keys never hardcoded

Parameterized secrets in workflows

Governed data access via Unity Catalog

ACID-compliant storage with time travel

ğŸ§  Skills Demonstrated

âœ” Data Engineering
âœ” ETL / ELT Pipelines
âœ” PySpark & Distributed Processing
âœ” Delta Lake & Data Lakehouse
âœ” Databricks Workflows
âœ” SQL Analytics
âœ” API Integration
âœ” Cloud Data Architecture
